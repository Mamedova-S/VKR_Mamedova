{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jt -t monokai -T -N -kl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install gensim\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import Tfidata_randomVectorizer\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neattext in c:\\users\\anana\\anaconda3\\lib\\site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install neattext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\anana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "nltk.download('vader_lexicon')\n",
    "import neattext.functions as nfx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_random=pd.read_csv('C:/projects/VKR_Mamedova/datasets/training.csv',encoding='ISO-8859-1',header=None)\n",
    "data_depressive= pd.read_csv('C:/projects/VKR_Mamedova/datasets/Suicide_Detection.csv')\n",
    "\n",
    "# word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# def load_google_vec(self):\n",
    "#     #url = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
    "#     #wget.download(url, 'Data/GoogleNews-vectors.bin.gz')\n",
    "#     return KeyedVectors.load_word2vec_format(\n",
    "#         'Data/GoogleNews-vectors.bin.gz',\n",
    "#         binary=True)\n",
    "\n",
    "\n",
    "# # Download link\n",
    "# # https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/view?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
    "# word2vec_path = 'GoogleNews-vectors-negative300.bin.gz' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1                             2         3  \\\n",
       "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                       4                                                  5  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>348103</td>\n",
       "      <td>If you don't like rock then your not going to ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>348106</td>\n",
       "      <td>You how you can tell i have so many friends an...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>348107</td>\n",
       "      <td>pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>348108</td>\n",
       "      <td>The usual stuff you find hereI'm not posting t...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>348110</td>\n",
       "      <td>I still haven't beaten the first boss in Hollo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232074 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                2  Ex Wife Threatening SuicideRecently I left my ...   \n",
       "1                3  Am I weird I don't get affected by compliments...   \n",
       "2                4  Finally 2020 is almost over... So I can never ...   \n",
       "3                8          i need helpjust help me im crying so hard   \n",
       "4                9  I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...   \n",
       "...            ...                                                ...   \n",
       "232069      348103  If you don't like rock then your not going to ...   \n",
       "232070      348106  You how you can tell i have so many friends an...   \n",
       "232071      348107  pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...   \n",
       "232072      348108  The usual stuff you find hereI'm not posting t...   \n",
       "232073      348110  I still haven't beaten the first boss in Hollo...   \n",
       "\n",
       "              class  \n",
       "0           suicide  \n",
       "1       non-suicide  \n",
       "2       non-suicide  \n",
       "3           suicide  \n",
       "4           suicide  \n",
       "...             ...  \n",
       "232069  non-suicide  \n",
       "232070  non-suicide  \n",
       "232071  non-suicide  \n",
       "232072      suicide  \n",
       "232073  non-suicide  \n",
       "\n",
       "[232074 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_depressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–∏–º –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü\n",
    "data_depressive = data_depressive.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>If you don't like rock then your not going to ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>You how you can tell i have so many friends an...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>The usual stuff you find hereI'm not posting t...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>I still haven't beaten the first boss in Hollo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232074 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        class\n",
       "0       Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
       "1       Am I weird I don't get affected by compliments...  non-suicide\n",
       "2       Finally 2020 is almost over... So I can never ...  non-suicide\n",
       "3               i need helpjust help me im crying so hard      suicide\n",
       "4       I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...      suicide\n",
       "...                                                   ...          ...\n",
       "232069  If you don't like rock then your not going to ...  non-suicide\n",
       "232070  You how you can tell i have so many friends an...  non-suicide\n",
       "232071  pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...  non-suicide\n",
       "232072  The usual stuff you find hereI'm not posting t...      suicide\n",
       "232073  I still haven't beaten the first boss in Hollo...  non-suicide\n",
       "\n",
       "[232074 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_depressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_depressive.drop('class', axis=1)\n",
    "y = data_depressive['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=data_random.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random.drop([1,2,3],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random.columns=['Label','Username','Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\d+)|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>Awww that s a bummer You shoulda got David Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can t update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>I dived many times for the ball Managed to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up Having no school is the best feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB com Very cool to hear old Walt interviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover Ask me fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy th Birthday to my boo of alll time Tupac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label         Username  \\\n",
       "0            0  _TheSpecialOne_   \n",
       "1            0    scotthamilton   \n",
       "2            0         mattycus   \n",
       "3            0          ElleCTF   \n",
       "4            0           Karoli   \n",
       "...        ...              ...   \n",
       "1599995      4  AmandaMarie1028   \n",
       "1599996      4      TheWDBoards   \n",
       "1599997      4           bpbabe   \n",
       "1599998      4     tinydiamondz   \n",
       "1599999      4   RyanTrevMorris   \n",
       "\n",
       "                                                      Text  \n",
       "0        Awww that s a bummer You shoulda got David Car...  \n",
       "1        is upset that he can t update his Facebook by ...  \n",
       "2        I dived many times for the ball Managed to sav...  \n",
       "3           my whole body feels itchy and like its on fire  \n",
       "4        no it s not behaving at all i m mad why am i h...  \n",
       "...                                                    ...  \n",
       "1599995  Just woke up Having no school is the best feel...  \n",
       "1599996   TheWDB com Very cool to hear old Walt interviews  \n",
       "1599997  Are you ready for your MoJo Makeover Ask me fo...  \n",
       "1599998  Happy th Birthday to my boo of alll time Tupac...  \n",
       "1599999                               happy charitytuesday  \n",
       "\n",
       "[1600000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_random['Text'] = data_random['Text'].apply(clean_tweet)\n",
    "data_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\anana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø—Ä–æ—Ü–µ—Å—Å—É —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–æ–ø —Å–ª–æ–≤ –∏ –ª–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# To remove emails\n",
    "email_regex = r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n",
    "regexes_to_remove = [email_regex, r'Subject:', r'Re:']\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    # removing all special charachter\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(X['text'][i]))\n",
    "    # make document as lowerCase\n",
    "    review = review.lower()\n",
    "    # splitting the documents into words for ex ['iam', 'omar']\n",
    "    review = review.split()\n",
    "    # make limmatization --> (change, changing, changes)---> (change)\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "    # join the document agian\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    # removing mails\n",
    "    for r in regexes_to_remove:\n",
    "        X['text'][i] = re.sub(r, '', review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "tfidf_vectorizer_n12 = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(X_train['text'])\n",
    "X_tfidf_test = tfidf_vectorizer.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_train_n12= tfidf_vectorizer_n12.fit_transform(X_train['text'])\n",
    "X_tfidf_test_n12=tfidf_vectorizer_n12.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "  \n",
    "X_bow_train = vectorizer.fit_transform(X_train['text'])\n",
    "X_bow_test = vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "def get_vador_scores(data):\n",
    "    sid=SIA()\n",
    "    vador_df=data.copy()\n",
    "    vador_df['scores'] = vador_df['text'].apply(lambda txt: sid.polarity_scores(str(txt)))\n",
    "    \n",
    "    vador_df['neg_score'] = vador_df['scores'].apply(lambda txt: txt['neg'])\n",
    "    vador_df['neu_score'] =vador_df['scores'].apply(lambda txt: txt['neu'])\n",
    "    vador_df['pos_score'] = vador_df['scores'].apply(lambda txt: txt['pos'])\n",
    "    vador_df['compound'] = vador_df['scores'].apply(lambda txt: txt['compound'])\n",
    "    vador_df.drop('scores', axis=1, inplace=True)\n",
    "    vador_df.drop('text', axis=1, inplace=True)\n",
    "    return vador_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vador_train = get_vador_scores(X_train)\n",
    "X_vador_test= get_vador_scores(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "281bf0cb9ee4d571eff4c2f5d6b84ce0c0bfe1e1cb074b260d2fbf8de124818f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
