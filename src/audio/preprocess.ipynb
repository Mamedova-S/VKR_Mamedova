{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "mount_file_id": "1R9uL0TFIaKV0CzKowIoAScTnJprqcSKs",
      "authorship_tag": "ABX9TyOsMXVy/2gxKqHlEW8fGukY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mamedova-S/VKR_Mamedova/blob/main/src/audio/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Импорт библиотек"
      ],
      "metadata": {
        "id": "m5FOEBYwvceR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EQUV8W9rvwzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786f674b-41da-4b63-c697-da890702e5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "4RXTJ6tswIPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPZ69A2bSncP"
      },
      "outputs": [],
      "source": [
        "!pip install numpy matplotlib scipy sklearn hmmlearn simplejson eyed3 pydub\n",
        "!pip install pyAudioAnalysis\n",
        "!pip install plot_metrics\n",
        "!pip install boto\n",
        "!pip install wget\n",
        "!pip install tensorflow keras\n",
        "\n",
        "\n",
        "# !pip install tensorflow.keras\n",
        "# !pip install tensorflow.keras.preprocessing.sequence\n",
        "# !pip install tensorflow.keras.utils\n",
        "# !pip install tensorflow.keras.preprocessing.text\n",
        "# !pip install tensorflow.keras.models\n",
        "# !pip install tensorflow.keras.layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "\n",
        "import fnmatch\n",
        "import zipfile\n",
        "\n",
        "\n",
        "import os\n",
        "import pyAudioAnalysis\n",
        "from pyAudioAnalysis import audioBasicIO as aIO\n",
        "from pyAudioAnalysis import audioSegmentation as aS\n",
        "\n",
        "\n",
        "import scipy.io.wavfile as wavfile\n",
        "import wave\n",
        "\n",
        "\n",
        "from numpy.lib import stride_tricks\n",
        "from PIL import Image\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import boto\n",
        "\n",
        "\n",
        "from scipy.io import wavfile as wav\n",
        "import asyncio\n",
        "\n",
        "# Metrics\n",
        "from sklearn import utils\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, \\\n",
        "        f1_score, precision_score, recall_score\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import boto\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "     \n",
        "\n",
        "# from pyAudioAnalysis.audioBasicIO import read_audio_file\n"
      ],
      "metadata": {
        "id": "7eLMCSVXS-B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Загрузка данных"
      ],
      "metadata": {
        "id": "hrJQ0Qw3TPLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Скачивание набора данных с https://dcapswoz.ict.usc.edu/"
      ],
      "metadata": {
        "id": "sz72QbuRTAxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir DAIC-WOZ\n",
        "%cd DAIC-WOZ"
      ],
      "metadata": {
        "id": "bVS3nlCoS_Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -r -np -nH --cut-dirs=3 -R index.html --user=daicwozuser --ask-password --no-check-certificate https://dcapswoz.ict.usc.edu/wwwdaicwoz/"
      ],
      "metadata": {
        "id": "rpLWXHPdS_73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Извлечение данных из архивов"
      ],
      "metadata": {
        "id": "x-DRzq_yTk4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Извлечение WAV-файлов и CSV-файлы расшифровки из ZIP-файлов."
      ],
      "metadata": {
        "id": "k5pGdxSRUTtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_files(zip_file, out_dir):\n",
        "\n",
        "    audio_dir = os.path.join(out_dir, 'audio')\n",
        "    if not os.path.exists(audio_dir):\n",
        "        os.makedirs(audio_dir)\n",
        "\n",
        "    transcripts_dir = os.path.join(out_dir, 'transcripts')\n",
        "    if not os.path.exists(audio_dir):\n",
        "        os.makedirs(transcripts_dir)\n",
        "\n",
        "    zip_ref = zipfile.ZipFile(zip_file)\n",
        "    for f in zip_ref.namelist(): \n",
        "        if f.endswith('.wav'):\n",
        "            zip_ref.extract(f, audio_dir)\n",
        "        elif fnmatch.fnmatch(f, '*TRANSCRIPT.csv'):\n",
        "            zip_ref.extract(f, transcripts_dir)\n",
        "    zip_ref.close()\n"
      ],
      "metadata": {
        "id": "0L49qB9HTAQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = '/content/DAIC-WOZ'\n",
        "\n",
        "out_dir = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/raw'\n",
        "\n",
        "for file in os.listdir(dir_name):\n",
        "    if file.endswith('.zip'):\n",
        "        zip_file = os.path.join(dir_name, file)\n",
        "        extract_files(zip_file, out_dir)"
      ],
      "metadata": {
        "id": "NevWe8otTAiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Предварительная обработка данных"
      ],
      "metadata": {
        "id": "KZcj5mNPTroz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Удаление тишины"
      ],
      "metadata": {
        "id": "EzhTqdSHU3fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_silence(filename, out_dir, smoothing=1.0, weight=0.3, plot=False):\n",
        "\n",
        "    partic_id = 'P' + filename.split('/')[-1].split('_')[0]  # PXXX\n",
        "    if is_segmentable(partic_id):\n",
        "        # создать каталог участника для сегментированных файлов wav\n",
        "        participant_dir = os.path.join(out_dir, partic_id)\n",
        "        if not os.path.exists(participant_dir):\n",
        "            os.makedirs(participant_dir)\n",
        "\n",
        "        os.chdir(participant_dir)\n",
        "\n",
        "        [Fs, x] = aIO.read_audio_file(filename)\n",
        "        segments = aS.silence_removal(x, Fs, 0.020, 0.020,\n",
        "                                     smooth_window=smoothing,\n",
        "                                     weight=weight,\n",
        "                                     plot=plot)\n",
        "\n",
        "        for s in segments:\n",
        "            seg_name = \"{:s}_{:.2f}-{:.2f}.wav\".format(partic_id, s[0], s[1])\n",
        "            wavfile.write(seg_name, Fs, x[int(Fs * s[0]):int(Fs * s[1])])\n",
        "\n",
        "        # объединить сегментированные волновые файлы в каталоге участников\n",
        "        concatenate_segments(participant_dir, partic_id)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "TKsQ2tXtTA1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Клипы ниже не были сегментированы из-за чрезмерной статики, близости к виртуальному интервьюеру, уровня громкости и т. д."
      ],
      "metadata": {
        "id": "9jE50Y31VJHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_segmentable(partic_id):\n",
        "\n",
        "    troubled = set(['P300', 'P305', 'P306', 'P308', 'P315', 'P316', 'P343',\n",
        "                    'P354', 'P362', 'P375', 'P378', 'P381', 'P382', 'P385',\n",
        "                    'P387', 'P388', 'P390', 'P392', 'P393', 'P395', 'P408',\n",
        "                    'P413', 'P421', 'P438', 'P473', 'P476', 'P479', 'P490',\n",
        "                    'P492'])\n",
        "    return partic_id not in troubled\n",
        "\n",
        "\n",
        "# 342, 373, 394, 398, 402, 416, 417, 444, 451, 458, 460, 480\n"
      ],
      "metadata": {
        "id": "8t1nkZQyTBHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_segments(participant_dir, partic_id, remove_segment=True):\n",
        "    infiles = os.listdir(participant_dir) # список wav-файлов в каталоге\n",
        "    outfile = '{}_no_silence.wav'.format(partic_id)\n",
        "\n",
        "    data = []\n",
        "    for infile in infiles:\n",
        "        w = wave.open(infile, 'rb')\n",
        "        data.append([w.getparams(), w.readframes(w.getnframes())])\n",
        "        w.close()\n",
        "        if remove_segment:\n",
        "            os.remove(infile)\n",
        "\n",
        "    output = wave.open(outfile, 'wb')\n",
        "    output.setparams(data[0][0])\n",
        "\n",
        "    for idx in range(len(data)):\n",
        "        output.writeframes(data[idx][1])\n",
        "    output.close()"
      ],
      "metadata": {
        "id": "wVGY-M4bTBYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyAudioAnalysis\n",
        "help(pyAudioAnalysis.audioSegmentation)"
      ],
      "metadata": {
        "id": "2N_v2A5fRibi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prefix = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/raw/audio/'\n",
        "if __name__ == '__main__':\n",
        "    dir_name = prefix\n",
        "    out_dir = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/raw/segmented_audio/'\n",
        "\n",
        "    for file in os.listdir(dir_name):\n",
        "        if file.endswith('.wav'):\n",
        "            filename = os.path.join(dir_name, file)\n",
        "            remove_silence(filename, out_dir)\n",
        "    print(\"All files saved successfully\")\n",
        "     "
      ],
      "metadata": {
        "id": "CbEI-uaXTBoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9256b2f-fd28-4f81-bf0a-dc848d10a87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Создание матриц спектограмм\n",
        "Создание матрицы спектрограмм из wav-файлов, которые можно передать нейросети CNN\n"
      ],
      "metadata": {
        "id": "T5Yec-_uvRwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/'\n",
        "\n",
        "df_train = pd.read_csv(prefix+'train_split_Depression_AVEC2017.csv')\n",
        "df_test = pd.read_csv(prefix+'dev_split_Depression_AVEC2017.csv')\n",
        "df_dev = pd.concat([df_train, df_test], axis=0)"
      ],
      "metadata": {
        "id": "akqZW3sO2dWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Кратковременное преобразование Фурье звукового сигнала.\n",
        "def stft(sig, frameSize, overlapFac=0.5, window=np.hanning):\n",
        "\n",
        "    win = window(frameSize)\n",
        "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
        "    samples = np.append(np.zeros((np.floor(frameSize/2.0).astype(int))), sig)\n",
        "    cols = np.ceil((len(samples) - frameSize) / float(hopSize)) + 1\n",
        "    cols=cols.astype(int)\n",
        "    samples = np.append(samples, np.zeros(frameSize))\n",
        "    frames = stride_tricks.as_strided(samples, shape=(cols, frameSize),\n",
        "                                      strides=(samples.strides[0]*hopSize,\n",
        "                                      samples.strides[0])).copy()\n",
        "    frames *= win\n",
        "\n",
        "    return np.fft.rfft(frames)\n"
      ],
      "metadata": {
        "id": "wgfPk66uTCDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Логарифмически масштабируем ось частоты.\n",
        "\n",
        "\n",
        "def logscale_spec(spec, sr=44100, factor=20.):\n",
        "\n",
        "    timebins, freqbins = np.shape(spec)\n",
        "\n",
        "    scale = np.linspace(0, 1, freqbins) ** factor\n",
        "    scale *= (freqbins-1)/max(scale)\n",
        "    scale = np.unique(np.round(scale))\n",
        "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
        "    for i in range(0, len(scale)):\n",
        "        if i == len(scale)-1:\n",
        "            newspec[:, i] = np.sum(spec[:, int(scale[i]):], axis=1)\n",
        "        else:\n",
        "            newspec[:, i] = np.sum(spec[:,int(scale[i]):int(scale[i+1])], axis=1)\n",
        "    allfreqs = np.abs(np.fft.fftfreq(freqbins*2, 1./sr)[:freqbins+1])\n",
        "    freqs = []\n",
        "    for i in range(0, len(scale)):\n",
        "        if i == len(scale)-1:\n",
        "            freqs += [np.mean(allfreqs[int(scale[i]):])]\n",
        "        else:\n",
        "            freqs += [np.mean(allfreqs[int(scale[i]):int(scale[i+1])])]\n",
        "\n",
        "    return newspec, freqs"
      ],
      "metadata": {
        "id": "TZhMm3bYTCPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая преобразует wav-файл в спектрограмму, \n",
        "# представленную матрицей, где строки представляют интервалы частот, \n",
        "# столбцы представляют время, а значения матрицы представляют интенсивность в децибелах. \n",
        "# Матрица этой формы может быть передана в качестве входных данных CNN после нормализации.\n",
        "\n",
        "def stft_matrix(audiopath, binsize=2**10, png_name='tmp.png',\n",
        "                save_png=False, offset=0):\n",
        "\n",
        "    samplerate, samples = wav.read(audiopath)\n",
        "    s = stft(samples, binsize)\n",
        "    sshow, freq = logscale_spec(s, factor=1, sr=samplerate)\n",
        "    ims = 20.*np.log10(np.abs(sshow)/10e-6)  \n",
        "    timebins, freqbins = np.shape(ims)\n",
        "    ims = np.transpose(ims)\n",
        "    ims = np.flipud(ims) \n",
        "    if save_png:\n",
        "        create_png(ims, png_name)\n",
        "\n",
        "    return ims"
      ],
      "metadata": {
        "id": "HoFrsKT4TCY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранить  png спектрограммы.\n",
        "\n",
        "def create_png(im_matrix, png_name):\n",
        "    image = Image.fromarray(im_matrix)\n",
        "    image = image.convert('L') # преобразовать в оттенки серого\n",
        "    image.save(png_name)\n"
      ],
      "metadata": {
        "id": "z3ZxeacJTCk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/raw/segmented_audio/'\n",
        "\n",
        "\n",
        "# просматривает wav-файлы в каталоге dir_name и создает png-файлы спектрограмм.\n",
        "# Это визуальное представление того, что передается в CNN до нормализации, \n",
        "# хотя на самом деле передается обрезанное матричное представление.\n",
        "for subdir, dirs, files in os.walk(dir_name):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            wav_file = os.path.join(subdir, file)\n",
        "            png_name = subdir + '/' + file[:-4] + '.png'\n",
        "            print('Processing ' + file + '...')\n",
        "            stft_matrix(wav_file, png_name=png_name, save_png=True)\n",
        "            "
      ],
      "metadata": {
        "id": "ienk7qjrTCsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Создание словарей спектограмм\n",
        "Этот сценарий создает словари для депрессивных и недепрессивных классов с идентификатором каждого участника в качестве ключа и соответствующим сегментированным матричным представлением спектрограммы в качестве значения. Затем указанные значения могут быть обрезаны и выбраны случайным образом в качестве входных данных для CNN.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GCf3uMDuyWcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Создает словарь участников с депрессией и участников без депрессии \n",
        "# с идентификатором участника в качестве ключа и матричным представлением \n",
        "# wav-файла no_silence в качестве значения. Затем эти значения этого словаря \n",
        "# случайным образом обрезаются и выбираются для создания \n",
        "# сбалансированных входных данных класса и динамика для CNN.\n",
        "\n",
        "def build_class_dictionaries(dir_name):\n",
        "    depressed_dict = dict()\n",
        "    normal_dict = dict()\n",
        "    for subdir, dirs, files in os.walk(dir_name):\n",
        "        for file in files:\n",
        "            if file.endswith('no_silence.wav'):\n",
        "                partic_id = int(file.split('_')[0][1:])\n",
        "                if in_dev_split(partic_id):\n",
        "                    wav_file = os.path.join(subdir, file)\n",
        "                    # матричное представление спектрограммы\n",
        "                    mat = stft_matrix(wav_file)\n",
        "                    depressed = get_depression_label(partic_id)  # 1 if True\n",
        "                    if depressed:\n",
        "                        depressed_dict[partic_id] = mat\n",
        "                    elif not depressed:\n",
        "                        normal_dict[partic_id] = mat\n",
        "    return depressed_dict, normal_dict"
      ],
      "metadata": {
        "id": "YdBJghy-3_BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Возвращает True, если участник находится в разделении разработки AVEC \n",
        "# (он же участник, для которого у нас есть ярлыки депрессии)\n",
        "\n",
        "def in_dev_split(partic_id):\n",
        "    return partic_id in set(df_dev['Participant_ID'].values)\n"
      ],
      "metadata": {
        "id": "8Byu8XBk3--q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Возвращает двоичную метку участника PHQ8. 1 представляет депрессию;\n",
        "# 0 означает отсутствие депрессии.\n",
        "\n",
        "def get_depression_label(partic_id):\n",
        "    return df_dev.loc[df_dev['Participant_ID'] ==\n",
        "                      partic_id]['PHQ8_Binary'].item()"
      ],
      "metadata": {
        "id": "eUspEeqb3-8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    dir_name = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/raw/segmented_audio/'\n",
        "    depressed_dict, normal_dict = build_class_dictionaries(dir_name)"
      ],
      "metadata": {
        "id": "iaWvPeBz3-5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"depressed_dict: \",len(depressed_dict))"
      ],
      "metadata": {
        "id": "6_A3bNow3-27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772bedbf-dea2-4bac-be21-bf737902f1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depressed_dict:  38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"normal_dict:\",len(normal_dict))"
      ],
      "metadata": {
        "id": "5_WTVHlO7FxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af5e91a-2847-40d4-cae8-7cb1b97c897c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal_dict: 84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Random Sampling\n",
        "\n",
        "Существует большой дисбаланс данных между положительными и отрицательными образцами,что влечет за собой большую погрешность в классификации. Количество недепрессивных субъектов примерно в четыре раза больше, чем у депрессивных. Если использовать эти образцы для обучения, модель будет иметь сильный уклон к недепрессивным данным.\n",
        "Чтобы решить эту проблему, я выполняю случайную выборку каждой из спектрограмм участников определенной ширины (времени) и постоянной высоты (частоты), чтобы гарантировать, чтобы в CNN было равное соотношение для каждого испытуемого и каждого класса. \n"
      ],
      "metadata": {
        "id": "BbALiw6lypVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модуль возвращает 40 случайных 4-секундных спектрограмм для каждого участника. Затем участники из каждого класса случайным образом выбираются в равной пропорции в качестве входных данных для сверточной нейронной сети (CNN). Это был важный шаг в уменьшении систематической ошибки модели."
      ],
      "metadata": {
        "id": "UBBZthzw089T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(15)  # for reproducibility\n",
        "# access_key = os.environ['AWS_ACCESS_KEY_ID']\n",
        "# access_secret_key = os.environ['AWS_SECRET_ACCESS_KEY']\n",
        "\n",
        "\n",
        "# Находит самый короткий клип во всем наборе данных, который, \n",
        "# в соответствии с нашей стратегией случайной выборки, ограничит \n",
        "# количество выборок, которые мы берем из каждого клипа, \n",
        "# чтобы убедиться, что наши классы сбалансированы.\n",
        "\n",
        "def determine_num_crops(depressed_dict, normal_dict, crop_width=125):\n",
        "    merged_dict = dict(normal_dict, **{str(k): v for k, v in depressed_dict.items()})\n",
        "    shortest_clip = min(merged_dict.items(), key=lambda x: x[1].shape[1])\n",
        "    shortest_pixel_width = shortest_clip[1].shape[1]\n",
        "    num_samples_from_clips = shortest_pixel_width / crop_width\n",
        "    return num_samples_from_clips"
      ],
      "metadata": {
        "id": "AJOVACN13-0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_class_sample_dict(segmented_audio_dict, n_samples, crop_width):\n",
        "    class_samples_dict = dict()\n",
        "    for partic_id, clip_mat in segmented_audio_dict.items():\n",
        "            samples = get_random_samples(clip_mat, n_samples, crop_width)\n",
        "            class_samples_dict[partic_id] = samples\n",
        "    return class_samples_dict"
      ],
      "metadata": {
        "id": "OrBgYQJ83-xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_samples(matrix, n_samples, crop_width):\n",
        "    clipped_mat = matrix[:, (matrix.shape[1] % crop_width):]\n",
        "    n_splits = clipped_mat.shape[1] / crop_width\n",
        "    #print(\"clipped_mat\",type(clipped_mat))\n",
        "    #print(\"n_splits\",type(n_splits))\n",
        "    cropped_sample_ls = np.split(clipped_mat, n_splits, axis=1)\n",
        "    #print(\"cropped_sample_ls\",type(cropped_sample_ls))\n",
        "    #print(\"n_samples\",type(n_samples))\n",
        "    samples = random.sample(cropped_sample_ls, int(n_samples))\n",
        "    return samples\n"
      ],
      "metadata": {
        "id": "5V9_k2Qk3-vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_dicts(crop_width):\n",
        "    # строим словари участников и сегментированную аудиоматрицу\n",
        "    # depressed_dict, normal_dict = build_class_dictionaries('/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/raw/segmented_audio')\n",
        "    n_samples = determine_num_crops(depressed_dict, normal_dict,\n",
        "                                    crop_width=crop_width)\n",
        "    # получить n_sample случайных выборок от каждого депрессивного участника\n",
        "    depressed_samples = build_class_sample_dict(depressed_dict, n_samples,\n",
        "                                                crop_width)\n",
        "    # получить n_sample случайных выборок от каждого участника, не страдающего депрессией\n",
        "    normal_samples = build_class_sample_dict(normal_dict, n_samples,\n",
        "                                             crop_width)\n",
        "    \n",
        "    # пройдемся по словарям выборок и сохраните файл npz со случайно выбранными n_samples для каждого участника.\n",
        "    \n",
        "    # сохранить депрессивные массивы в .npz\n",
        "    for key, _ in depressed_samples.items():\n",
        "        path = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data/'\n",
        "        filename = 'D{}.npz'.format(key)\n",
        "        outfile = path + filename\n",
        "        np.savez(outfile, *depressed_samples[key])\n",
        "    # сохранить недепрессивные массивы .npz\n",
        "    for key, _ in normal_samples.items():\n",
        "        path = '/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data/'\n",
        "        filename = 'N{}.npz'.format(key)\n",
        "        outfile = path + filename\n",
        "        np.savez(outfile, *normal_samples[key])"
      ],
      "metadata": {
        "id": "wQqtn--e3-sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Учитывая обрезанные сегменты от каждого класса и участника, \n",
        "# эта функция определяет, сколько образцов мы можем взять от каждого участника \n",
        "# и сколько участников мы можем взять от каждого класса.\n",
        "\n",
        "def rand_samp_train_test_split(npz_file_dir):\n",
        "    npz_files = os.listdir(npz_file_dir)\n",
        "\n",
        "    dep_samps = [f for f in npz_files if f.startswith('D')]\n",
        "    norm_samps = [f for f in npz_files if f.startswith('N')]\n",
        "    max_samples = min(len(dep_samps), len(norm_samps))\n",
        "    dep_select_samps = np.random.choice(dep_samps, size=max_samples,\n",
        "                                        replace=False)\n",
        "    norm_select_samps = np.random.choice(norm_samps, size=max_samples,\n",
        "                                         replace=False)\n",
        "    test_size = 0.2\n",
        "    num_test_samples = int(len(dep_select_samps) * test_size)\n",
        "\n",
        "    train_samples = []\n",
        "    for sample in dep_select_samps[:-num_test_samples]:\n",
        "        npz_file = npz_file_dir + '/' + sample\n",
        "        with np.load(npz_file) as data:\n",
        "            for key in data.keys():\n",
        "                train_samples.append(data[key])\n",
        "    for sample in norm_select_samps[:-num_test_samples]:\n",
        "        npz_file = npz_file_dir + '/' + sample\n",
        "        with np.load(npz_file) as data:\n",
        "            for key in data.keys():\n",
        "                train_samples.append(data[key])\n",
        "    #y=(np.ones(len(train_samples)//2),np.zeros(len(train_samples)//2))\n",
        "    #print(\"y:\",y)\n",
        "    train_labels = np.concatenate((np.ones(len(train_samples)//2),\n",
        "                                   np.zeros(len(train_samples)//2)))\n",
        "    test_samples = []\n",
        "    for sample in dep_select_samps[-num_test_samples:]:\n",
        "        npz_file = npz_file_dir + '/' + sample\n",
        "        with np.load(npz_file) as data:\n",
        "            for key in data.keys():\n",
        "                test_samples.append(data[key])\n",
        "    for sample in norm_select_samps[-num_test_samples:]:\n",
        "        npz_file = npz_file_dir + '/' + sample\n",
        "        with np.load(npz_file) as data:\n",
        "            for key in data.keys():\n",
        "                test_samples.append(data[key])\n",
        "    test_labels = np.concatenate((np.ones(len(test_samples)//2),\n",
        "                                  np.zeros(len(test_samples)//2)))\n",
        "\n",
        "    return np.array(train_samples), train_labels, np.array(test_samples), \\\n",
        "        test_labels"
      ],
      "metadata": {
        "id": "fSx9t2Ew4UVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# построить обрезанные npz-файлы участника, это все no_silence интервью участника, \n",
        "# но каждый массив в npz-файлах имеет ширину crop_width\n",
        "\n",
        "create_sample_dicts(crop_width=125)\n",
        "\n",
        "# случайная выборка из npz-файлов участников для обеспечения баланса классов\n",
        "train_samples, train_labels, test_samples, test_labels = rand_samp_train_test_split('/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data')\n",
        "\n",
        "# save as npz locally\n",
        "print(\"Saving npz file locally...\")\n",
        "np.savez('/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data/train_samples.npz', train_samples)\n",
        "np.savez('/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data/train_labels.npz', train_labels)\n",
        "np.savez('/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data/test_samples.npz', test_samples)\n",
        "np.savez('/content/drive/MyDrive/Colab Notebooks/VKR_Depression/Dataset/Randomly_Sampled_Data/test_labels.npz', test_labels)\n",
        "print(\"Saved Locally\")"
      ],
      "metadata": {
        "id": "N1qz94xx4UQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9b6c80-fe41-4ec4-fb05-b421a4ca6eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving npz file locally...\n",
            "Saved Locally\n"
          ]
        }
      ]
    }
  ]
}